{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AML_Adv_10_GAN.ipynb","provenance":[{"file_id":"https://github.com/sarvasvkulpati/intro_to_gans/blob/master/intro_to_gans.ipynb","timestamp":1591480819432}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Cd6FTEVrsWTg","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import keras\n","from keras.layers import Dense, Dropout, Input\n","from keras.models import Model,Sequential\n","from keras.datasets import mnist\n","from tqdm import tqdm\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.optimizers import Adam\n","from keras.utils import plot_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKvfmiwdsWWe","colab_type":"code","colab":{}},"source":["def load_data():\n","    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n","    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n","    \n","    # convert shape of x_train from (60000, 28, 28) to (60000, 784) \n","    # 784 columns per row\n","    x_train = x_train.reshape(60000, 784)\n","    return (x_train, y_train, x_test, y_test)\n","    \n","(X_train, y_train,X_test, y_test)=load_data()\n","print(X_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rBKBuSSrNBUJ","colab_type":"text"},"source":["We use the Adam optimizer (a combination of Adagrad and RMSprop.) as it is computationally efficient, and has very low memory requirement. Adam is "]},{"cell_type":"code","metadata":{"id":"W3RAdpQwsWaj","colab_type":"code","colab":{}},"source":["def adam_optimizer():\n","    return Adam(lr=0.0002, beta_1=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1iHwk42XsWdV","colab_type":"code","colab":{}},"source":["def create_generator():\n","    generator=Sequential()\n","    generator.add(Dense(units=256,input_dim=100))\n","    generator.add(LeakyReLU(0.2))\n","    \n","    generator.add(Dense(units=512))\n","    generator.add(LeakyReLU(0.2))\n","    \n","    generator.add(Dense(units=1024))\n","    generator.add(LeakyReLU(0.2))\n","    \n","    generator.add(Dense(units=784, activation='tanh'))\n","    \n","    generator.compile(loss='binary_crossentropy', optimizer=adam_optimizer())\n","    return generator\n","\n","g = create_generator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HMkCH2hiPBgp","colab_type":"code","colab":{}},"source":["g.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VBG4SHF1PBd4","colab_type":"code","colab":{}},"source":["plot_model(g, show_shapes=True, show_layer_names=True,\n","    rankdir='TB', expand_nested=True, dpi=96)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U_NLmrTHsWgg","colab_type":"code","colab":{}},"source":["def create_discriminator():\n","    discriminator=Sequential()\n","    discriminator.add(Dense(units=1024,input_dim=784))\n","    discriminator.add(LeakyReLU(0.2))\n","    discriminator.add(Dropout(0.3))\n","       \n","    \n","    discriminator.add(Dense(units=512))\n","    discriminator.add(LeakyReLU(0.2))\n","    discriminator.add(Dropout(0.3))\n","       \n","    discriminator.add(Dense(units=256))\n","    discriminator.add(LeakyReLU(0.2))\n","    \n","    discriminator.add(Dense(units=1, activation='sigmoid'))\n","    \n","    discriminator.compile(loss='binary_crossentropy', optimizer=adam_optimizer())\n","    return discriminator\n","\n","d = create_discriminator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LnkBxpxxPgik","colab_type":"code","colab":{}},"source":["d.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IDFHaHtoPgfk","colab_type":"code","colab":{}},"source":["plot_model(d, show_shapes=True, show_layer_names=True,\n","    rankdir='TB', expand_nested=True, dpi=96)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XUWO7l62sWmQ","colab_type":"code","colab":{}},"source":["def create_gan(discriminator, generator):\n","    discriminator.trainable=False\n","    gan_input = Input(shape=(100,))\n","    x = generator(gan_input)\n","    gan_output = discriminator(x)\n","    gan = Model(inputs=gan_input, outputs=gan_output)\n","    gan.compile(loss='binary_crossentropy', optimizer='adam')\n","    return gan\n","    \n","gan = create_gan(d,g)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iv_R0tA4QADh","colab_type":"code","colab":{}},"source":["gan.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MbVGPsCdQPaM","colab_type":"code","colab":{}},"source":["plot_model(gan, show_shapes=True, show_layer_names=True,\n","    rankdir='TB', expand_nested=True, dpi=96)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tt0AksuMsWpH","colab_type":"code","colab":{}},"source":["def plot_generated_images(epoch, generator, examples=100, dim=(10,10), figsize=(10,10)):\n","    noise= np.random.normal(loc=0, scale=1, size=[examples, 100])\n","    generated_images = generator.predict(noise)\n","    generated_images = generated_images.reshape(100,28,28)\n","    plt.figure(figsize=figsize)\n","    for i in range(generated_images.shape[0]):\n","        plt.subplot(dim[0], dim[1], i+1)\n","        plt.imshow(generated_images[i], interpolation='nearest')\n","        plt.axis('off')\n","    plt.tight_layout()\n","    plt.savefig('gan_generated_image %d.png' %epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"up1MRf84sWsA","colab_type":"code","colab":{}},"source":["def training(epochs=1, batch_size=128):\n","    \n","    #Loading the data\n","    (X_train, y_train, X_test, y_test) = load_data()\n","    batch_count = X_train.shape[0] / batch_size\n","    \n","    # Creating GAN\n","    generator = create_generator()\n","    discriminator = create_discriminator()\n","    gan = create_gan(discriminator, generator)\n","    \n","    for e in range(1,epochs+1 ):\n","        print(\"Epoch %d\" %e)\n","        for _ in tqdm(range(batch_size)):\n","        #generate  random noise as an input  to  initialize the  generator\n","            noise= np.random.normal(0,1, [batch_size, 100])\n","            \n","            # Generate fake MNIST images from noised input\n","            generated_images = generator.predict(noise)\n","            \n","            # Get a random set of  real images\n","            image_batch =X_train[np.random.randint(low=0,high=X_train.shape[0],size=batch_size)]\n","            \n","            #Construct different batches of  real and fake data \n","            X= np.concatenate([image_batch, generated_images])\n","            \n","            # Labels for generated and real data\n","            y_dis=np.zeros(2*batch_size)\n","            y_dis[:batch_size]=0.9\n","            \n","            #Pre train discriminator on  fake and real data  before starting the gan. \n","            discriminator.trainable=True\n","            discriminator.train_on_batch(X, y_dis)\n","            \n","            #Tricking the noised input of the Generator as real data\n","            noise= np.random.normal(0,1, [batch_size, 100])\n","            y_gen = np.ones(batch_size)\n","            \n","            # During the training of gan, \n","            # the weights of discriminator should be fixed. \n","            # We can enforce that by setting the trainable flag\n","            discriminator.trainable=False\n","            \n","            # training the GAN by alternating the training of the Discriminator \n","            # and training the chained GAN model with Discriminatorâ€™s weights freezed\n","            gan.train_on_batch(noise, y_gen)\n","            \n","        if e == 1 or e % 20 == 0:\n","            plot_generated_images(e, generator)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yq8waMN-a1tl","colab_type":"text"},"source":["Careful about the # of epochs..."]},{"cell_type":"code","metadata":{"id":"cOvZnqeWa0A4","colab_type":"code","colab":{}},"source":["%%time\n","training(400,128)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RFpKuhnOs7x-","colab_type":"code","colab":{}},"source":["!ls\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"50j3Oey8s7vN","colab_type":"code","colab":{}},"source":["from IPython.display import Image\n","Image(\"gan_generated_image 400.png\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0XIQH_Q3s7tA","colab_type":"code","colab":{}},"source":["import imageio\n","import glob\n","\n","anim_file = 'GAN_animated.gif'\n","\n","with imageio.get_writer(anim_file, mode='I') as writer:\n","  filenames = glob.glob('gan_generated_image *.png')\n","  filenames = sorted(filenames)\n","  last = -1\n","  for i,filename in enumerate(filenames):\n","    frame = 10*(i**0.5)\n","    if round(frame) > round(last):\n","      last = frame\n","    else:\n","      continue\n","    image = imageio.imread(filename)\n","    writer.append_data(image)\n","  image = imageio.imread(filename)\n","  writer.append_data(image)\n","\n","#import IPython\n","#if IPython.version_info > (6,2,0,''):\n","#  display.Image(filename=anim_file)\n","\n","try:\n","  from google.colab import files\n","except ImportError:\n","   pass\n","else:\n","  files.download(anim_file)"],"execution_count":null,"outputs":[]}]}