{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.16"},"colab":{"name":"AML_Adv_3_Voting.ipynb","provenance":[],"collapsed_sections":["Xfi_boTqVWl8","alaDn3Eu2Tfq","J3pAAJil3Bko"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Xfi_boTqVWl8","colab_type":"text"},"source":["# Compare classifiers and combine them into an ensemble with soft/hard voting"]},{"cell_type":"markdown","metadata":{"id":"alaDn3Eu2Tfq","colab_type":"text"},"source":["## <font color=red>Exercise 1</font>"]},{"cell_type":"markdown","metadata":{"id":"nDJcQQUQ2MyR","colab_type":"text"},"source":["1. Load the *MNIST* data and split it into a training set, a validation set, and a test set (e.g. use 50k instances for training, and 10k each for validation and testing). \n","2. Then train various classifiers, such as a **Random Forest** classifier, an **Extra-Trees** classifier, and an **SVM** classifier, for example. If you want, pick more.\n","3. Next, try to combine them into an **ensemble** that outperforms each individual classifier on the validation set, using **soft or hard voting**. \n","4. Once you have found one, try it on the test set. How much better does it perform compared to the individual classifiers?"]},{"cell_type":"markdown","metadata":{"id":"J3pAAJil3Bko","colab_type":"text"},"source":["### <font color='green'>Solution</font>"]},{"cell_type":"code","metadata":{"id":"TooSpz1K3Bcb","colab_type":"code","colab":{}},"source":["# type your code below"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DyXnXpclezsG","colab_type":"text"},"source":["_Credits: Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (2nd Edition) by Aurélien Géron, O'Reilly Media Inc., 2019_"]}]}